{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning in RUL Estimation\n",
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "nominated-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries in python\n",
    "import argparse\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import importlib\n",
    "from itertools import repeat\n",
    "from scipy.stats import randint, expon, uniform\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import cv2\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Ignore tf err log\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "# random seed predictable\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Path settings\n",
    "current_dir = '.'#os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "## Dataset path\n",
    "train_FD001_path = current_dir +'/cmapss/train_FD001.csv'\n",
    "test_FD001_path = current_dir +'/cmapss/test_FD001.csv'\n",
    "RUL_FD001_path = current_dir+'/cmapss/RUL_FD001.txt'\n",
    "FD001_path = [train_FD001_path, test_FD001_path, RUL_FD001_path]\n",
    "\n",
    "train_FD002_path = current_dir +'/cmapss/train_FD002.csv'\n",
    "test_FD002_path = current_dir +'/cmapss/test_FD002.csv'\n",
    "RUL_FD002_path = current_dir +'/cmapss/RUL_FD002.txt'\n",
    "FD002_path = [train_FD002_path, test_FD002_path, RUL_FD002_path]\n",
    "\n",
    "train_FD003_path = current_dir +'/cmapss/train_FD003.csv'\n",
    "test_FD003_path = current_dir +'/cmapss/test_FD003.csv'\n",
    "RUL_FD003_path = current_dir +'/cmapss/RUL_FD003.txt'\n",
    "FD003_path = [train_FD003_path, test_FD003_path, RUL_FD003_path]\n",
    "\n",
    "train_FD004_path =current_dir +'/cmapss/train_FD004.csv'\n",
    "test_FD004_path = current_dir +'/cmapss/test_FD004.csv'\n",
    "RUL_FD004_path = current_dir +'/cmapss/RUL_FD004.txt'\n",
    "FD004_path = [train_FD004_path, test_FD004_path, RUL_FD004_path]\n",
    "\n",
    "## Assign columns name\n",
    "cols = ['unit_nr', 'cycles', 'os_1', 'os_2', 'os_3']\n",
    "cols += ['sensor_{0:02d}'.format(s + 1) for s in range(26)]\n",
    "col_rul = ['RUL_truth']\n",
    "\n",
    "## Read csv file to pandas dataframe\n",
    "FD_path = [\"none\", FD001_path, FD002_path, FD003_path, FD004_path]\n",
    "dp_str = [\"none\", \"FD001\", \"FD002\", \"FD003\", \"FD004\"]\n",
    "\n",
    "## temporary model path for NN\n",
    "model_path = current_dir +'/temp_net.h5'\n",
    "\n",
    "# Sensors not to be considered (those that do not disclose any pattern in their ts)\n",
    "sensor_drop = ['sensor_01', 'sensor_05', 'sensor_06', 'sensor_10', 'sensor_16', 'sensor_18', 'sensor_19']\n",
    "\n",
    "#start = time.time()\n",
    "\n",
    "# Architecture preferences\n",
    "dp = FD_path[1]\n",
    "subdataset = dp_str[1]\n",
    "sequence_length = 32\n",
    "thres_type = None\n",
    "thres_value = 50\n",
    "device = 'cpu'\n",
    "method = 'rps'\n",
    "n_hidden1 = 100\n",
    "n_hidden2 = 10\n",
    "epochs = 1000\n",
    "batch = 700\n",
    "verbose = 2\n",
    "flatten = False\n",
    "visualize = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Plot File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created on April , 2021\n",
    "@author:\n",
    "'''\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from pyts.image import RecurrencePlot\n",
    "from sklearn import preprocessing\n",
    "# from sklearn.decomposition import PCA\n",
    "# from pyts.approximation import SymbolicFourierApproximation\n",
    "\n",
    "\n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "    # for one id I put all the rows in a single matrix\n",
    "    data_matrix = id_df[seq_cols].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "    # Iterate over two lists in parallel.\n",
    "\n",
    "    for start, stop in zip(range(0, num_elements - seq_length), range(seq_length, num_elements)):\n",
    "        yield data_matrix[start:stop, :]\n",
    "\n",
    "def gen_labels(id_df, seq_length, label):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "    # For one id I put all the labels in a single matrix.\n",
    "    data_matrix = id_df[label].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "    # I have to remove the first seq_length labels\n",
    "    # because for one id the first sequence of seq_length size have as target\n",
    "    # the last label (the previus ones are discarded).\n",
    "    # All the next id's sequences will have associated step by step one label as target.\n",
    "    return data_matrix[seq_length:num_elements, :]\n",
    "\n",
    "\n",
    "\n",
    "class input_gen(object):\n",
    "    '''\n",
    "    class for data preparation (rps generator)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, data_path_list, sequence_length, sensor_drop, piecewise_lin_ref=125, preproc=False, visualize=True):\n",
    "        '''\n",
    "        :param data_path_list: python list of four sub-dataset\n",
    "        :param sequence_length: legnth of sequence (sliced time series)\n",
    "        :param sensor_drop: sensors not to be considered\n",
    "        :param piecewise_lin_ref: max rul value (if real rul value is larger than piecewise_lin_ref,\n",
    "        then the rul value is piecewise_lin_ref)\n",
    "        :param preproc: preprocessing\n",
    "        '''\n",
    "        # self.__logger = logging.getLogger('data preparation for using it as the network input')\n",
    "        self.data_path_list = data_path_list\n",
    "        self.sequence_length = sequence_length\n",
    "        self.sensor_drop = sensor_drop\n",
    "        self.preproc = preproc\n",
    "        self.piecewise_lin_ref = piecewise_lin_ref\n",
    "        self.visualize = visualize\n",
    "\n",
    "\n",
    "        ## Assign columns name\n",
    "        cols = ['unit_nr', 'cycles', 'os_1', 'os_2', 'os_3']\n",
    "        cols += ['sensor_{0:02d}'.format(s + 1) for s in range(26)]\n",
    "        col_rul = ['RUL_truth']\n",
    "\n",
    "        train_FD = pd.read_csv(self.data_path_list[0], sep=' ', header=None,\n",
    "                               names=cols, index_col=False)\n",
    "        test_FD = pd.read_csv(self.data_path_list[1], sep=' ', header=None,\n",
    "                              names=cols, index_col=False)\n",
    "        RUL_FD = pd.read_csv(self.data_path_list[2], sep=' ', header=None,\n",
    "                             names=col_rul, index_col=False)\n",
    "\n",
    "        ## Calculate RUL and append to train data\n",
    "        # get the time of the last available measurement for each unit\n",
    "        mapper = {}\n",
    "        for unit_nr in train_FD['unit_nr'].unique():\n",
    "            mapper[unit_nr] = train_FD['cycles'].loc[train_FD['unit_nr'] == unit_nr].max()\n",
    "\n",
    "        # calculate RUL = time.max() - time_now for each unit\n",
    "        train_FD['RUL'] = train_FD['unit_nr'].apply(lambda nr: mapper[nr]) - train_FD['cycles']\n",
    "        # piecewise linear for RUL labels\n",
    "        train_FD['RUL'].loc[(train_FD['RUL'] > self.piecewise_lin_ref)] = self.piecewise_lin_ref\n",
    "\n",
    "        # Cut max RUL ground truth\n",
    "        RUL_FD['RUL_truth'].loc[(RUL_FD['RUL_truth'] > self.piecewise_lin_ref)] = self.piecewise_lin_ref\n",
    "\n",
    "        ## Excluse columns which only have NaN as value\n",
    "        cols_nan = train_FD.columns[train_FD.isna().any()].tolist()\n",
    "        cols_const = [col for col in train_FD.columns if len(train_FD[col].unique()) <= 2]\n",
    "\n",
    "        ## Drop exclusive columns\n",
    "        # train_FD = train_FD.drop(columns=cols_const + cols_nan)\n",
    "        # test_FD = test_FD.drop(columns=cols_const + cols_nan)\n",
    "\n",
    "        train_FD = train_FD.drop(columns=cols_const + cols_nan + sensor_drop)\n",
    "\n",
    "        test_FD = test_FD.drop(columns=cols_const + cols_nan + sensor_drop)\n",
    "\n",
    "\n",
    "        if self.preproc == True:\n",
    "            ## preprocessing(normailization for the neural networks)\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "            # for the training set\n",
    "            # train_FD['cycles_norm'] = train_FD['cycles']\n",
    "            cols_normalize = train_FD.columns.difference(['unit_nr', 'cycles', 'os_1', 'os_2', 'RUL'])\n",
    "\n",
    "            norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_FD[cols_normalize]),\n",
    "                                         columns=cols_normalize,\n",
    "                                         index=train_FD.index)\n",
    "            join_df = train_FD[train_FD.columns.difference(cols_normalize)].join(norm_train_df)\n",
    "            train_FD = join_df.reindex(columns=train_FD.columns)\n",
    "\n",
    "            # for the test set\n",
    "            # test_FD['cycles_norm'] = test_FD['cycles']\n",
    "            cols_normalize_test = test_FD.columns.difference(['unit_nr', 'cycles', 'os_1', 'os_2'])\n",
    "            # print (\"cols_normalize_test\", cols_normalize_test)\n",
    "            norm_test_df = pd.DataFrame(min_max_scaler.transform(test_FD[cols_normalize_test]), columns=cols_normalize_test,\n",
    "                                        index=test_FD.index)\n",
    "            test_join_df = test_FD[test_FD.columns.difference(cols_normalize_test)].join(norm_test_df)\n",
    "            test_FD = test_join_df.reindex(columns=test_FD.columns)\n",
    "            test_FD = test_FD.reset_index(drop=True)\n",
    "        else:\n",
    "            # print (\"No preprocessing\")\n",
    "            pass\n",
    "\n",
    "        # Specify the columns to be used\n",
    "        sequence_cols_train = train_FD.columns.difference(['unit_nr', 'cycles', 'os_1', 'os_2', 'RUL'])\n",
    "        sequence_cols_test = test_FD.columns.difference(['unit_nr', 'os_1', 'os_2', 'cycles'])\n",
    "\n",
    "\n",
    "\n",
    "        ## generator for the sequences\n",
    "        # transform each id of the train dataset in a sequence\n",
    "        seq_gen = (list(gen_sequence(train_FD[train_FD['unit_nr'] == id], self.sequence_length, sequence_cols_train))\n",
    "                   for id in train_FD['unit_nr'].unique())\n",
    "\n",
    "        # generate sequences and convert to numpy array in training set\n",
    "        seq_array_train = np.concatenate(list(seq_gen)).astype(np.float32)\n",
    "        self.seq_array_train = seq_array_train.transpose(0, 2, 1) # shape = (samples, sensors, sequences)\n",
    "        # print(\"seq_array_train.shape\", self.seq_array_train.shape)\n",
    "\n",
    "        # generate label of training samples\n",
    "        label_gen = [gen_labels(train_FD[train_FD['unit_nr'] == id], self.sequence_length, ['RUL'])\n",
    "                     for id in train_FD['unit_nr'].unique()]\n",
    "        self.label_array_train = np.concatenate(label_gen).astype(np.float32)\n",
    "\n",
    "        # generate sequences and convert to numpy array in test set (only the last sequence for each engine in test set)\n",
    "        seq_array_test_last = [test_FD[test_FD['unit_nr'] == id][sequence_cols_test].values[-self.sequence_length:]\n",
    "                               for id in test_FD['unit_nr'].unique() if\n",
    "                               len(test_FD[test_FD['unit_nr'] == id]) >= self.sequence_length]\n",
    "\n",
    "        seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n",
    "        self.seq_array_test_last = seq_array_test_last.transpose(0, 2, 1) # shape = (samples, sensors, sequences)\n",
    "        # print(\"seq_array_test_last.shape\", self.seq_array_test_last.shape)\n",
    "\n",
    "        # generate label of test samples\n",
    "        y_mask = [len(test_FD[test_FD['unit_nr'] == id]) >= self.sequence_length for id in test_FD['unit_nr'].unique()]\n",
    "        label_array_test_last = RUL_FD['RUL_truth'][y_mask].values\n",
    "        self.label_array_test = label_array_test_last.reshape(label_array_test_last.shape[0], 1).astype(np.float32)\n",
    "\n",
    "\n",
    "        ## Visualize Run-2-failure TS of the first engine in the training set.(Please deactivate after understanding)\n",
    "        if self.visualize == True:\n",
    "            # R2F TS of the first engine\n",
    "            pd.DataFrame(train_FD[train_FD['unit_nr'] == 1][sequence_cols_train].values,\n",
    "                             columns=sequence_cols_train).plot(subplots=True, figsize=(15, 15))\n",
    "\n",
    "            # The last sequences sliced from each TS (of the first engine)\n",
    "            prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "            colors = prop_cycle.by_key()['color']\n",
    "            colors = colors + colors + colors\n",
    "\n",
    "            seq_gen = (\n",
    "            list(gen_sequence(train_FD[train_FD['unit_nr'] == id], self.sequence_length, sequence_cols_train))\n",
    "            for id in train_FD['unit_nr'].unique())\n",
    "\n",
    "            seq_list_engine = list(seq_gen)\n",
    "            seq_engine_1_array = np.asarray(seq_list_engine[0])\n",
    "\n",
    "            last_seq_engine_1_array = seq_engine_1_array[-1, :, :]\n",
    "            fig_ts = plt.figure(figsize=(15, 15))\n",
    "            for s in range(last_seq_engine_1_array.shape[1]):\n",
    "                seq_s = last_seq_engine_1_array[:, s]\n",
    "                # plt.subplot(last_seq_engine_1_array.shape[1],(s//4) + 1, (s%4)+1)\n",
    "                plt.subplot(4, 4, s + 1)\n",
    "                plt.plot(seq_s, \"y\", label=sequence_cols_train[s], color=colors[s])\n",
    "                plt.legend()\n",
    "\n",
    "            plt.xlabel(\"time(cycles)\")\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def rps(self, thres_type=None, thres_percentage=50, flatten=False, visualize=True):\n",
    "        '''\n",
    "        generate RPs from sequences\n",
    "        :param thres_type:  ‘point’, ‘distance’ or None (default = None)\n",
    "        :param thres_percentage:\n",
    "        :param flatten:\n",
    "        :param visualize: visualize generated RPs (first training sample)\n",
    "        :return: PRs (samples for NNs and their label)\n",
    "        '''\n",
    "\n",
    "        # Recurrence plot transformation for training samples\n",
    "        rp_train = RecurrencePlot(threshold=thres_type, percentage=thres_percentage,flatten=flatten)\n",
    "\n",
    "        rp_list = []\n",
    "        for idx in range(self.seq_array_train.shape[0]):\n",
    "            temp_mts = self.seq_array_train[idx]\n",
    "            # print (temp_mts.shape)\n",
    "            X_rp_temp = rp_train.fit_transform(temp_mts)\n",
    "            # print (X_rp_temp.shape)\n",
    "            rp_list.append(X_rp_temp)\n",
    "\n",
    "        rp_train_samples = np.stack(rp_list, axis=0)\n",
    "\n",
    "        # Recurrence plot transformation for test samples\n",
    "        rp_test = RecurrencePlot(threshold=thres_type, percentage=thres_percentage, flatten=flatten)\n",
    "        rp_list = []\n",
    "        for idx in range(self.seq_array_test_last.shape[0]):\n",
    "            temp_mts = self.seq_array_test_last[idx]\n",
    "            # print (temp_mts.shape)\n",
    "            X_rp_temp = rp_test.fit_transform(temp_mts)\n",
    "            # print (X_rp_temp.shape)\n",
    "            rp_list.append(X_rp_temp)\n",
    "        rp_test_samples = np.stack(rp_list, axis=0)\n",
    "\n",
    "        label_array_train = self.label_array_train\n",
    "        label_array_test = self.label_array_test\n",
    "\n",
    "        # Visualize RPs of the last sequences sliced from each TS (of the first engine)\n",
    "        if visualize == True:\n",
    "            X_rp = rp_train_samples[-1]\n",
    "            plt.figure(figsize=(15, 15))\n",
    "            for s in range(len(X_rp)):\n",
    "                # plt.subplot(last_seq_engine_1_array.shape[1],(s//4) + 1, (s%4)+1)\n",
    "                plt.subplot(4, 4, s + 1)\n",
    "                if flatten == True:\n",
    "                    img = np.atleast_2d(X_rp[s])\n",
    "                    plt.imshow(img, extent=(0, img.shape[1], 0, round(img.shape[1]/9)))\n",
    "                else:\n",
    "                    plt.imshow(X_rp[s], origin='lower')\n",
    "                # plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        return  rp_train_samples, label_array_train, rp_test_samples, label_array_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "recovered-despite",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_class = input_gen(data_path_list=dp, sequence_length=sequence_length, sensor_drop= sensor_drop, visualize=visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 'rps':\n",
    "    train_samples, label_array_train, test_samples, label_array_test = data_class.rps(\n",
    "        thres_type=thres_type,\n",
    "        thres_percentage=thres_value,\n",
    "        flatten=flatten,\n",
    "        visualize=visualize)\n",
    "\n",
    "elif method == 'jrp': # please implement any method if needed\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 32, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[0] = 0\n",
    "train_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret '32' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5793db9c6197>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret '32' as a data type"
     ]
    }
   ],
   "source": [
    "np.repeat(np.zeros(32,32),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1- Creare due dummy zero arrays with np.zeros(32,32)\n",
    "# 2- Concatenate all 16 arrays\n",
    "# 3- Reshape the concatenated arrays to (128,128)\n",
    "# 4- Extract RGB channels with cv2.split(img)\n",
    "\n",
    "X_rp = train_samples[-1]\n",
    "print(X_rp[1].shape)\n",
    "print(len(X_rp))\n",
    "plt.figure(figsize=(10,10))\n",
    "for s in range(len(X_rp)):\n",
    "    # plt.subplot(last_seq_engine_1_array.shape[1],(s//4) + 1, (s%4)+1)\n",
    "    print(s)\n",
    "    # plt.subplot(4, 4, s + 1)\n",
    "    plt.imshow(X_rp[s], origin='lower')\n",
    "    # plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 32)\n"
     ]
    }
   ],
   "source": [
    "def change_format(X_rp)\n",
    "    # Dato che sono 14 sensori allora concateno i 14 giá esistenti a due zeros. \n",
    "    temp = np.zeros((64,32))\n",
    "    for i in range(len(X_rp)):\n",
    "        x = X_rp[i]\n",
    "        temp = np.concatenate((temp,x), axis=0)\n",
    "\n",
    "    # Temp ora ha 514x32 \n",
    "    new_train0 = temp.reshape(128,128)\n",
    "    # To make a figure without the frame :\n",
    "    my_dpi = 96\n",
    "    array_size = 128\n",
    "    fig = plt.figure(figsize=(array_size/my_dpi, array_size/my_dpi), dpi=my_dpi, frameon=False)\n",
    "    #To make the content fill the whole figure\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    #Then draw your image on it :\n",
    "    ax.imshow(new_train0)\n",
    "    fig.savefig('img1.png', dpi = my_dpi)\n",
    "    img = cv2.imread('img1.png')\n",
    "    return np.asarray(cv2.split(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importantissimo\n",
    "#im = Image.fromarray(np.uint8(new_train0*255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FB667B1FA90>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 128x128 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 128, 128)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(cv2.split(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[84, 84, 84, ..., 84, 84, 84],\n",
       "        [84, 84, 84, ..., 84, 84, 84],\n",
       "        [84, 84, 84, ..., 84, 84, 84],\n",
       "        ...,\n",
       "        [87, 87, 85, ..., 84, 87, 84],\n",
       "        [87, 85, 85, ..., 84, 88, 85],\n",
       "        [88, 88, 87, ..., 85, 85, 84]],\n",
       "\n",
       "       [[ 1,  1,  1, ...,  1,  1,  1],\n",
       "        [ 1,  1,  1, ...,  1,  1,  1],\n",
       "        [ 1,  1,  1, ...,  1,  1,  1],\n",
       "        ...,\n",
       "        [ 3,  3,  2, ...,  1,  3,  1],\n",
       "        [ 3,  2,  2, ...,  1,  5,  2],\n",
       "        [ 5,  5,  3, ...,  2,  2,  1]],\n",
       "\n",
       "       [[68, 68, 68, ..., 68, 68, 68],\n",
       "        [68, 68, 68, ..., 68, 68, 68],\n",
       "        [68, 68, 68, ..., 68, 68, 68],\n",
       "        ...,\n",
       "        [68, 68, 68, ..., 68, 68, 68],\n",
       "        [68, 68, 68, ..., 68, 69, 68],\n",
       "        [69, 69, 68, ..., 68, 68, 68]]], dtype=uint8)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(cv2.split(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1ecdc159f0cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Creare i 3 canali rgb dalla libreria di opencv messa nei requirements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_train0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_train0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_train0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "# Creare i 3 canali rgb dalla libreria di opencv messa nei requirements\n",
    "\n",
    "b, g, r = new_train0[:, :, 0], new_train0[:, :, 1], new_train0[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "vocal-spectacular",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_samples.shape:  (17431, 14, 32, 32)\n",
      "label_array_train.shape:  (17431, 1)\n",
      "test_samples.shape:  (99, 14, 32, 32)\n",
      "label_array_test.shape:  (99, 1)\n",
      "train_samples.reshape:  (17431, 32, 32, 14)\n"
     ]
    }
   ],
   "source": [
    "print (\"train_samples.shape: \", train_samples.shape) # shape = (samples, sensors, height, width)\n",
    "print (\"label_array_train.shape: \", label_array_train.shape) # shape = (samples, label)\n",
    "print (\"test_samples.shape: \", test_samples.shape) # shape = (samples, sensors, height, width)\n",
    "print (\"label_array_test.shape: \", label_array_test.shape) # shape = (samples, ground truth)\n",
    "\n",
    "# train_samples, test_samples = concat_vec(train_samples, test_samples)\n",
    "train_samples = train_samples.reshape(train_samples.shape[0],32,32,14)\n",
    "print(\"train_samples.reshape: \", train_samples.shape)\n",
    "# print (\"train_samples.shape: \", train_samples.shape) # shape = (samples, sensors, height, width)\n",
    "# print (\"label_array_train.shape: \", label_array_train.shape) # shape = (samples, label)\n",
    "# print (\"test_samples.shape: \", test_samples.shape) # shape = (samples, sensors, height, width)\n",
    "# print (\"label_array_test.shape: \", label_array_test.shape) # shape = (samples, ground truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import logging as log\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import importlib\n",
    "from scipy.stats import randint, expon, uniform\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from math import sqrt\n",
    "# import keras\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# import keras.backend as K\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Embedding\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, LSTM, TimeDistributed\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "\n",
    "def gen_net():\n",
    "    '''\n",
    "    TODO: Generate and evaluate any CNN instead of MLPs\n",
    "    :param vec_len:\n",
    "    :param num_hidden1:\n",
    "    :param num_hidden2:\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "\n",
    "    # input_shape deve essere 30x30, cioé la grandezza dell'immagine di training che abbiamo\n",
    "    # il parametro include_top parametrizzato a false indica che non verrá caricato l'ultimo layer\n",
    "    vgg = VGG16(input_shape=(32,32,3), weights = 'imagenet', include_top = False)\n",
    "\n",
    "    # Passaggio fondamentale é non trainare i pesi esistenti in vgg\n",
    "    for layer in vgg.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    \n",
    "    base_outputs = vgg.output\n",
    "    final_outputs = Dense(1)(base_outputs)\n",
    "    new_model = Model(inputs = vgg.input, outputs = final_outputs) \n",
    "    new_model.summary()\n",
    "\n",
    "    return new_model\n",
    "\n",
    "\n",
    "# def gen_net(vec_len, num_hidden1, num_hidden2 ):\n",
    "#     '''\n",
    "#     TODO: Generate and evaluate any CNN instead of MLPs\n",
    "#     :param vec_len:\n",
    "#     :param num_hidden1:\n",
    "#     :param num_hidden2:\n",
    "#     :return:\n",
    "#     '''\n",
    "\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(num_hidden1, activation='relu', input_shape=(vec_len,)))\n",
    "#     model.add(Dense(num_hidden2, activation='relu'))\n",
    "#     model.add(Dense(1))\n",
    "\n",
    "#     return model\n",
    "\n",
    "class network_fit(object):\n",
    "    '''\n",
    "    class for network\n",
    "    '''\n",
    "\n",
    "    def __init__(self, train_samples, label_array_train, test_samples, label_array_test,\n",
    "                 model_path, n_hidden1 =100, n_hidden2 =10, verbose=1):\n",
    "        '''\n",
    "        Constructor\n",
    "        Generate a NN and train\n",
    "        @param none\n",
    "        '''\n",
    "        # self.__logger = logging.getLogger('data preparation for using it as the network input')\n",
    "        self.train_samples = train_samples\n",
    "        self.label_array_train = label_array_train\n",
    "        self.test_samples = test_samples\n",
    "        self.label_array_test = label_array_test\n",
    "        self.n_hidden1 = n_hidden1\n",
    "        self.n_hidden2 = n_hidden2\n",
    "        self.model_path = model_path\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # self.mlps = gen_net(self.train_samples.shape[1], self.n_hidden1, self.n_hidden2)\n",
    "        self.mlps = gen_net()\n",
    "\n",
    "\n",
    "\n",
    "    def train_net(self, epochs = 1000, batch_size= 700, lr= 1e-05, plotting=True):\n",
    "        '''\n",
    "        specify the optimizers and train the network\n",
    "        :param epochs:\n",
    "        :param batch_size:\n",
    "        :param lr:\n",
    "        :return:\n",
    "        '''\n",
    "        print(\"Initializing network...\")\n",
    "        # compile the model\n",
    "        rp = optimizers.RMSprop(learning_rate=lr, rho=0.9, centered=True)\n",
    "        adm = optimizers.Adam(learning_rate=lr, epsilon=1)\n",
    "        sgd_m = optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "        keras_rmse = tf.keras.metrics.RootMeanSquaredError()\n",
    "        self.mlps.compile(loss='mean_squared_error', optimizer=sgd_m, metrics=[keras_rmse, 'mae'])\n",
    "\n",
    "        print(self.mlps.summary())\n",
    "\n",
    "        # Train the model\n",
    "        history = self.mlps.fit(self.train_samples, self.label_array_train, epochs=epochs, batch_size=batch_size,\n",
    "                                validation_split=0.2, verbose=self.verbose,\n",
    "                                callbacks=[\n",
    "                               EarlyStopping(monitor='val_root_mean_squared_error', min_delta=0, patience=50, verbose=self.verbose, mode='min'),\n",
    "                               ModelCheckpoint(self.model_path, monitor='val_root_mean_squared_error', save_best_only=True, mode='min',\n",
    "                                               verbose=self.verbose)])\n",
    "\n",
    "        val_rmse_k = history.history['val_root_mean_squared_error']\n",
    "        val_rmse_min = min(val_rmse_k)\n",
    "        min_val_rmse_idx = val_rmse_k.index(min(val_rmse_k))\n",
    "        stop_epoch = min_val_rmse_idx +1\n",
    "        val_rmse_min = round(val_rmse_min, 4)\n",
    "        print (\"val_rmse_min: \", val_rmse_min)\n",
    "\n",
    "        trained_net = self.mlps\n",
    "\n",
    "        ## Plot training & validation loss about epochs\n",
    "        if plotting == True:\n",
    "            # summarize history for Loss\n",
    "            fig_acc = plt.figure(figsize=(10, 10))\n",
    "            plt.plot(history.history['loss'])\n",
    "            plt.plot(history.history['val_loss'])\n",
    "            plt.title('model loss')\n",
    "            plt.ylabel('loss')\n",
    "            plt.ylim(0, 2000)\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(['train', 'test'], loc='upper left')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        return trained_net\n",
    "\n",
    "\n",
    "\n",
    "    def test_net(self, trained_net=None, best_model=True, plotting=True):\n",
    "        '''\n",
    "        Evalute the trained network on test set\n",
    "        :param trained_net:\n",
    "        :param best_model:\n",
    "        :param plotting:\n",
    "        :return:\n",
    "        '''\n",
    "        # Load the trained model\n",
    "        if best_model:\n",
    "            estimator = load_model(self.model_path)\n",
    "        else:\n",
    "            estimator = load_model(trained_net)\n",
    "\n",
    "        # predict the RUL\n",
    "        y_pred_test = estimator.predict(self.test_samples)\n",
    "        y_true_test = self.label_array_test # ground truth of test samples\n",
    "\n",
    "        pd.set_option('display.max_rows', 1000)\n",
    "        test_print = pd.DataFrame()\n",
    "        test_print['y_pred'] = y_pred_test.flatten()\n",
    "        test_print['y_truth'] = y_true_test.flatten()\n",
    "        test_print['diff'] = abs(y_pred_test.flatten() - y_true_test.flatten())\n",
    "        test_print['diff(ratio)'] = abs(y_pred_test.flatten() - y_true_test.flatten()) / y_true_test.flatten()\n",
    "        test_print['diff(%)'] = (abs(y_pred_test.flatten() - y_true_test.flatten()) / y_true_test.flatten()) * 100\n",
    "\n",
    "        y_predicted = test_print['y_pred']\n",
    "        y_actual = test_print['y_truth']\n",
    "        rms = sqrt(mean_squared_error(y_actual, y_predicted)) # RMSE metric\n",
    "        test_print['rmse'] = rms\n",
    "        print(test_print)\n",
    "\n",
    "\n",
    "        # Score metric\n",
    "        h_array = y_predicted - y_actual\n",
    "        s_array = np.zeros(len(h_array))\n",
    "        for j, h_j in enumerate(h_array):\n",
    "            if h_j < 0:\n",
    "                s_array[j] = math.exp(-(h_j / 13)) - 1\n",
    "\n",
    "            else:\n",
    "                s_array[j] = math.exp(h_j / 10) - 1\n",
    "        score = np.sum(s_array)\n",
    "\n",
    "        # Plot the results of RUL prediction\n",
    "        if plotting == True:\n",
    "            fig_verify = plt.figure(figsize=(12, 6))\n",
    "            plt.plot(y_pred_test, color=\"blue\")\n",
    "            plt.plot(y_true_test, color=\"green\")\n",
    "            plt.title('prediction')\n",
    "            plt.ylabel('value')\n",
    "            plt.xlabel('row')\n",
    "            plt.legend(['predicted', 'actual data'], loc='upper left')\n",
    "            plt.show()\n",
    "\n",
    "        return rms, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "amino-courtesy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1, 1, 1)           513       \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 513\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creo la cnn tenendo conto che non ho concatenato gli input e che quindi non serviranno:\n",
    "# - Hidden\n",
    "# - Deve essere modificato nel gen_net lo shape da passare al costruttore perché é 30x30\n",
    "mlps_net = network_fit(train_samples, label_array_train, test_samples, label_array_test,\n",
    "                       model_path = model_path, n_hidden1=n_hidden1, n_hidden2=n_hidden2, verbose=verbose)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing network...\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 1, 1)           513       \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 513\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer model_1: expected shape=(None, 32, 32, 3), found shape=(None, 32, 32, 14)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5ef45c147123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlps_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-d9a174dec7df>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(self, epochs, batch_size, lr, plotting)\u001b[0m\n\u001b[1;32m    139\u001b[0m                                \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_root_mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                                ModelCheckpoint(self.model_path, monitor='val_root_mean_squared_error', save_best_only=True, mode='min',\n\u001b[0;32m--> 141\u001b[0;31m                                                verbose=self.verbose)])\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mval_rmse_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_root_mean_squared_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer model_1: expected shape=(None, 32, 32, 3), found shape=(None, 32, 32, 14)\n"
     ]
    }
   ],
   "source": [
    "trained_net = mlps_net.train_net(epochs=epochs, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms, score = mlps_net.test_net(trained_net)\n",
    "\n",
    "\n",
    "print(subdataset + \" test RMSE: \", rms)\n",
    "print(subdataset + \" test Score: \", score)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computing time: \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning and Fine Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 149, 149, 32) 864         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 149, 149, 32) 96          conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 149, 149, 32) 0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 147, 147, 32) 9216        activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 147, 147, 32) 96          conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 147, 147, 32) 0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 147, 147, 64) 18432       activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 147, 147, 64) 192         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 147, 147, 64) 0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 73, 73, 80)   240         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 73, 73, 80)   0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 71, 71, 192)  138240      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 71, 71, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 71, 71, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 35, 35, 64)   192         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 35, 35, 64)   0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 35, 35, 96)   55296       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 35, 35, 48)   144         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 35, 35, 96)   288         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 35, 35, 48)   0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 35, 35, 96)   0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 35, 35, 64)   76800       activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 35, 35, 96)   82944       activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 35, 35, 64)   192         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 35, 35, 64)   192         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 35, 35, 96)   288         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 35, 35, 32)   96          conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 35, 35, 64)   0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 35, 35, 64)   0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 35, 35, 96)   0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 35, 35, 32)   0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_129[0][0]             \n",
      "                                                                 activation_131[0][0]             \n",
      "                                                                 activation_134[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 35, 35, 64)   192         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 35, 35, 64)   0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 35, 35, 96)   55296       activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 35, 35, 48)   144         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 35, 35, 96)   288         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 35, 35, 48)   0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 35, 35, 96)   0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 35, 35, 64)   76800       activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 35, 35, 96)   82944       activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 35, 35, 64)   192         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 35, 35, 64)   192         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 35, 35, 96)   288         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 35, 35, 64)   192         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 35, 35, 64)   0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 35, 35, 64)   0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 35, 35, 96)   0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 35, 35, 64)   0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_136[0][0]             \n",
      "                                                                 activation_138[0][0]             \n",
      "                                                                 activation_141[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 35, 35, 64)   192         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 35, 35, 64)   0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 35, 35, 96)   55296       activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 35, 35, 48)   144         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 35, 35, 96)   288         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 35, 35, 48)   0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 35, 35, 96)   0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 35, 35, 64)   76800       activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 35, 35, 96)   82944       activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 35, 35, 64)   192         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 35, 35, 64)   192         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 35, 35, 96)   288         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 35, 35, 64)   192         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 35, 35, 64)   0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 35, 35, 64)   0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 35, 35, 96)   0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 35, 35, 64)   0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_143[0][0]             \n",
      "                                                                 activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "                                                                 activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 35, 35, 64)   192         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 35, 35, 64)   0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 35, 35, 96)   55296       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 35, 35, 96)   288         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 35, 35, 96)   0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 17, 17, 96)   82944       activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 17, 17, 384)  1152        conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 17, 17, 96)   288         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 17, 17, 384)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 17, 17, 96)   0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_150[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "                                                                 max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 17, 17, 128)  384         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 17, 17, 128)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 17, 17, 128)  114688      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 17, 17, 128)  384         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 17, 17, 128)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 17, 17, 128)  114688      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 17, 17, 128)  384         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 17, 17, 128)  384         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 17, 17, 128)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 17, 17, 128)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 17, 17, 128)  114688      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 17, 17, 128)  114688      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 17, 17, 128)  384         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 17, 17, 128)  384         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 17, 17, 128)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 17, 17, 128)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 17, 17, 192)  172032      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 17, 17, 192)  172032      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 17, 17, 192)  576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 17, 17, 192)  576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 17, 17, 192)  576         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 17, 17, 192)  576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 17, 17, 192)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 17, 17, 192)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 17, 17, 192)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 17, 17, 192)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 17, 17, 160)  480         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 17, 17, 160)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 17, 17, 160)  179200      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 17, 17, 160)  480         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 17, 17, 160)  0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 17, 17, 160)  179200      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 17, 17, 160)  480         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 17, 17, 160)  480         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 17, 17, 160)  0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 17, 17, 160)  0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 17, 17, 160)  179200      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 17, 17, 160)  179200      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 17, 17, 160)  480         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 17, 17, 160)  480         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 17, 17, 160)  0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 17, 17, 160)  0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 17, 17, 192)  215040      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 17, 17, 192)  215040      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 17, 17, 192)  576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 17, 17, 192)  576         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 17, 17, 192)  576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 17, 17, 192)  576         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 17, 17, 192)  0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 17, 17, 192)  0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 17, 17, 192)  0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 17, 17, 192)  0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_164[0][0]             \n",
      "                                                                 activation_167[0][0]             \n",
      "                                                                 activation_172[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 17, 17, 160)  480         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 17, 17, 160)  0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 17, 17, 160)  179200      activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 17, 17, 160)  480         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 17, 17, 160)  0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 17, 17, 160)  179200      activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 17, 17, 160)  480         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 17, 17, 160)  480         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 17, 17, 160)  0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 17, 17, 160)  0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 17, 17, 160)  179200      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 17, 17, 160)  179200      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 17, 17, 160)  480         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 17, 17, 160)  480         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 17, 17, 160)  0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 17, 17, 160)  0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 17, 17, 192)  215040      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 17, 17, 192)  215040      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 17, 17, 192)  576         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 17, 17, 192)  576         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 17, 17, 192)  576         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 17, 17, 192)  576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 17, 17, 192)  0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 17, 17, 192)  0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 17, 17, 192)  0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 17, 17, 192)  0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_174[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 17, 17, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 17, 17, 192)  0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 17, 17, 192)  258048      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 17, 17, 192)  576         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 17, 17, 192)  0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 17, 17, 192)  258048      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 17, 17, 192)  576         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 17, 17, 192)  576         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 17, 17, 192)  0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 17, 17, 192)  0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 17, 17, 192)  258048      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 17, 17, 192)  258048      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 17, 17, 192)  576         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 17, 17, 192)  576         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 17, 17, 192)  0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 17, 17, 192)  0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 17, 17, 192)  258048      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 17, 17, 192)  258048      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 17, 17, 192)  576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 17, 17, 192)  576         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 17, 17, 192)  576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 17, 17, 192)  576         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 17, 17, 192)  0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 17, 17, 192)  0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 17, 17, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 17, 17, 192)  0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_184[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "                                                                 activation_192[0][0]             \n",
      "                                                                 activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 17, 17, 192)  576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 17, 17, 192)  0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 17, 17, 192)  258048      activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 17, 17, 192)  576         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 17, 17, 192)  0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 17, 17, 192)  258048      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 17, 17, 192)  576         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 17, 17, 192)  576         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 17, 17, 192)  0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 17, 17, 192)  0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 8, 8, 320)    552960      activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 8, 8, 192)    331776      activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 8, 8, 320)    960         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 8, 8, 192)    576         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 8, 8, 320)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 8, 8, 192)    0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_195[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 8, 8, 448)    1344        conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 8, 8, 448)    0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 8, 8, 384)    1548288     activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 8, 8, 384)    1152        conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 8, 8, 384)    1152        conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 8, 8, 384)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 8, 8, 384)    0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 8, 8, 384)    442368      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 8, 8, 384)    442368      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 8, 8, 384)    442368      activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 8, 8, 384)    442368      activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 8, 8, 384)    1152        conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 8, 8, 384)    1152        conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 8, 8, 384)    1152        conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 8, 8, 384)    1152        conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 8, 8, 320)    960         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 8, 8, 384)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 8, 8, 384)    0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 8, 8, 384)    0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 8, 8, 384)    0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 8, 8, 192)    576         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 8, 8, 320)    0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_202[0][0]             \n",
      "                                                                 activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_206[0][0]             \n",
      "                                                                 activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 8, 8, 192)    0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_200[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 8, 8, 448)    1344        conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 8, 8, 448)    0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 8, 8, 384)    1548288     activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 8, 8, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 8, 8, 384)    1152        conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 8, 8, 384)    0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 8, 8, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 8, 8, 384)    442368      activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 8, 8, 384)    442368      activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 8, 8, 384)    442368      activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 8, 8, 384)    442368      activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 8, 8, 384)    1152        conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 8, 8, 384)    1152        conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 8, 8, 384)    1152        conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 8, 8, 384)    1152        conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 8, 8, 320)    960         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 8, 8, 384)    0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 8, 8, 384)    0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 8, 8, 384)    0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 8, 8, 384)    0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 8, 8, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 8, 8, 320)    0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_211[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 768)    0           activation_215[0][0]             \n",
      "                                                                 activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 8, 8, 192)    0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_209[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,851,784\n",
      "Trainable params: 23,817,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# example of loading the inception v3 model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# load model\n",
    "new_input = tf.keras.Input(30,30,3)\n",
    "model = InceptionV3()\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
